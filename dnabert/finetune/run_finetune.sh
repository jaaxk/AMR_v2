#!/bin/bash
#SBATCH -p a100-long
#SBATCH -t 24:00:00
#SBATCH --gres=gpu:4
#SBATCH --mem 250G
#SBATCH --output logs/res_%j.txt

# script to run finetuning of DNABERT model
# ensure it is run in the same directory as train.py
# expects DATA_PATH to be directory with train.csv, test.csv, dev.csv. These should be generated by data/train_dev_split.py


source /gpfs/scratch/jvaska/miniconda3/etc/profile.d/conda.sh #for conda envs to work
conda activate dna

# paths
export DATA_PATH="data/dnabert_finetune_dataset_v1" #this needs to be a directory with train.csv, dev.csv, test.csv
export RUN_NAME="full_model_species_only_v1" #name of run for wandb and output directory
export OUT_DIR="finetuned_models/${RUN_NAME}"
export MODEL_PATH="pretrained_models/bacteria_model"

export WANDB_NAME=${RUN_NAME}

# training params
export EPOCHS=20
export MAX_LENGTH=250 #should be 1/4 of the length of the sequences
export num_gpu=4
export OMP_NUM_THREADS=16
export EVAL_AND_SAVE_STEPS=400 

# hyperparams to tune
export LR=3e-5
export WARMUP_STEPS=100
export TRAIN_BATCH_SIZE=8 #limited by memory
export GRADIENT_ACCUMULATION_STEPS=1


wandb login 0e16ac7c39d857e9bc3de95f06818dd4899bc8c1

echo "Running finetuning with dataset $DATA_PATH and run name $RUN_NAME"

# **relative path to train.py**
torchrun --nproc_per_node=${num_gpu} train.py \
    --model_name_or_path ${MODEL_PATH} \
    --data_path  ${DATA_PATH} \
    --kmer -1 \
    --run_name ${RUN_NAME} \
    --model_max_length ${MAX_LENGTH} \
    --per_device_train_batch_size ${TRAIN_BATCH_SIZE} \
    --per_device_eval_batch_size 16 \
    --gradient_accumulation_steps ${GRADIENT_ACCUMULATION_STEPS} \
    --learning_rate ${LR} \
    --num_train_epochs ${EPOCHS} \
    --fp16 \
    --save_steps ${EVAL_AND_SAVE_STEPS} \
    --output_dir ${OUT_DIR} \
    --evaluation_strategy steps \
    --eval_steps ${EVAL_AND_SAVE_STEPS} \
    --warmup_steps ${WARMUP_STEPS} \
    --logging_steps 100 \
    --overwrite_output_dir True \
    --log_level info \
    --find_unused_parameters False \

export BEST_MODEL_DIR=$OUT_DIR/best
echo "Best model directory: $BEST_MODEL_DIR"
#move additional files to best model directory for inference
cp ${MODEL_PATH}/bert_layers.py ${MODEL_PATH}/bert_padding.py ${MODEL_PATH}/configuration_bert.py ${MODEL_PATH}/flash_attention_triton.py ${MODEL_PATH}/__init__.py $BEST_MODEL_DIR

cp $0 $BEST_MODEL_DIR/run_script.txt #copy this script to best model directory for record keeping



