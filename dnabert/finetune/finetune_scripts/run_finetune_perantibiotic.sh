#!/bin/bash
#SBATCH -p a100-long
#SBATCH -t 48:00:00
#SBATCH --gres=gpu:4
#SBATCH --mem 250G
#SBATCH --output logs/res_%j.txt

# script to run finetuning of DNABERT model
# ensure it is run one directory above train.py
# expects DATA_PATH to be directory with train.csv, test.csv, dev.csv. These should be generated by dnabert/finetune/data/dnabert_preprocessing.py


source /gpfs/scratch/jvaska/miniconda3/etc/profile.d/conda.sh #for conda envs to work
conda activate dna

# paths
export DATA_DIR="../data/per_antibiotic/finetune_augment_TESTSPLIT_v3" #this is base dir containing per antibiotic directories with train/test/dev each
export BASE_RUN_NAME="per_antibiotic_models_v3" #base run name, _{antibiotic} will be attached
export BASE_OUT_DIR="../finetuned_models/${BASE_RUN_NAME}"
export MODEL_PATH="../pretrained_models/bacteria_model"


# training params
export EPOCHS=8
export MAX_LENGTH=250 #should be 1/4 of the length of the sequences
export num_gpu=4
export OMP_NUM_THREADS=16
export EVAL_AND_SAVE_STEPS=1000

# hyperparams to tune
export LR=3e-5
export WARMUP_STEPS=1000 #~5% of total steps
export TRAIN_BATCH_SIZE=8 #limited by memory
export GRADIENT_ACCUMULATION_STEPS=4 #simulate larger batch size (effective batch size = batch_size*gradient_accumulation_steps*num_gpus)


wandb login 0e16ac7c39d857e9bc3de95f06818dd4899bc8c1

for ANTIBIOTIC in $(ls -d ${DATA_DIR}/*); do
    ANTIBIOTIC=$(basename ${ANTIBIOTIC})
    echo "Running finetuning for antibiotic: $ANTIBIOTIC"
    export WANDB_NAME=${BASE_RUN_NAME}_${ANTIBIOTIC}
    export RUN_NAME=${BASE_RUN_NAME}_${ANTIBIOTIC}
    export OUT_DIR=${BASE_OUT_DIR}/${ANTIBIOTIC}
    export DATA_PATH=${DATA_DIR}/${ANTIBIOTIC}

    echo "Running finetuning with dataset $DATA_PATH and run name $RUN_NAME"



    # **relative path to train.py**
    torchrun --nproc_per_node=${num_gpu} ../train.py \
        --model_name_or_path ${MODEL_PATH} \
        --data_path  ${DATA_PATH} \
        --kmer -1 \
        --run_name ${RUN_NAME} \
        --model_max_length ${MAX_LENGTH} \
        --per_device_train_batch_size ${TRAIN_BATCH_SIZE} \
        --per_device_eval_batch_size 16 \
        --gradient_accumulation_steps ${GRADIENT_ACCUMULATION_STEPS} \
        --learning_rate ${LR} \
        --num_train_epochs ${EPOCHS} \
        --fp16 \
        --save_steps ${EVAL_AND_SAVE_STEPS} \
        --output_dir ${OUT_DIR} \
        --evaluation_strategy steps \
        --eval_steps ${EVAL_AND_SAVE_STEPS} \
        --warmup_steps ${WARMUP_STEPS} \
        --logging_steps 100 \
        --overwrite_output_dir True \
        --log_level info \
        --find_unused_parameters False \

    export BEST_MODEL_DIR=$OUT_DIR/best
    echo "Best model directory: $BEST_MODEL_DIR"
    #move additional files to best model directory for inference
    cp ${MODEL_PATH}/bert_layers.py ${MODEL_PATH}/bert_padding.py ${MODEL_PATH}/configuration_bert.py ${MODEL_PATH}/flash_attn_triton.py ${MODEL_PATH}/__init__.py $BEST_MODEL_DIR

    cp $0 $BEST_MODEL_DIR/run_script.txt #copy this script to best model directory for record keeping


done
